{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dvclive import Live"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sets the current active experiment to the \"Apple_Models\" experiment and\n",
    "# returns the Experiment metadata\n",
    "experiment = mlflow.set_experiment(\"fmnist_pytorch_Models2\")\n",
    "\n",
    "# Define a run name for this iteration of training.\n",
    "# If this is not set, a unique name will be auto-generated for your run.\n",
    "run_name = \"fmnist_nn_test_s4\"\n",
    "\n",
    "# Define an artifact path that the model will be saved to.\n",
    "#artifact_path = \"fmnist_nn\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchinfo import summary\n",
    "from torchmetrics import Accuracy\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "from pathlib import Path\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26421880/26421880 [00:17<00:00, 1522995.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/FashionMNIST/raw/train-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29515/29515 [00:00<00:00, 253310.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4422102/4422102 [00:03<00:00, 1376838.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5148/5148 [00:00<00:00, 55364812.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Download training data from open datasets.\n",
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "\n",
    "# Create data loaders.\n",
    "train_dataloader = DataLoader(training_data, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get cpu or gpu for training.\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "\n",
    "# Define the model.\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28 * 28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# DVC Report\n",
       "\n",
       "params.yaml\n",
       "\n",
       "|   epochs |   learning_rate |   batch_size | loss_function    | metric_function    | optimizer   |\n",
       "|----------|-----------------|--------------|------------------|--------------------|-------------|\n",
       "|        5 |           0.001 |           64 | CrossEntropyLoss | MulticlassAccuracy | SGD         |\n",
       "\n",
       "metrics.json\n",
       "\n",
       "|   step |\n",
       "|--------|\n",
       "|   4689 |\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.302391 accuracy: 0.125000 [0 / 938]\n",
      "loss: 2.289646 accuracy: 0.187500 [100 / 938]\n",
      "loss: 2.267756 accuracy: 0.250000 [200 / 938]\n",
      "loss: 2.261332 accuracy: 0.234375 [300 / 938]\n",
      "loss: 2.235206 accuracy: 0.296875 [400 / 938]\n",
      "loss: 2.199858 accuracy: 0.343750 [500 / 938]\n",
      "loss: 2.218194 accuracy: 0.281250 [600 / 938]\n",
      "loss: 2.171138 accuracy: 0.375000 [700 / 938]\n",
      "loss: 2.182675 accuracy: 0.250000 [800 / 938]\n",
      "loss: 2.136302 accuracy: 0.359375 [900 / 938]\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 2.155216 accuracy: 0.281250 [0 / 938]\n",
      "loss: 2.139678 accuracy: 0.296875 [100 / 938]\n",
      "loss: 2.076361 accuracy: 0.437500 [200 / 938]\n",
      "loss: 2.090477 accuracy: 0.421875 [300 / 938]\n",
      "loss: 2.014881 accuracy: 0.531250 [400 / 938]\n",
      "loss: 1.953932 accuracy: 0.546875 [500 / 938]\n",
      "loss: 1.988659 accuracy: 0.390625 [600 / 938]\n",
      "loss: 1.894318 accuracy: 0.484375 [700 / 938]\n",
      "loss: 1.918155 accuracy: 0.390625 [800 / 938]\n",
      "loss: 1.824279 accuracy: 0.546875 [900 / 938]\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 1.879495 accuracy: 0.453125 [0 / 938]\n",
      "loss: 1.837179 accuracy: 0.453125 [100 / 938]\n",
      "loss: 1.717929 accuracy: 0.531250 [200 / 938]\n",
      "loss: 1.760115 accuracy: 0.531250 [300 / 938]\n",
      "loss: 1.629145 accuracy: 0.609375 [400 / 938]\n",
      "loss: 1.594972 accuracy: 0.640625 [500 / 938]\n",
      "loss: 1.621888 accuracy: 0.578125 [600 / 938]\n",
      "loss: 1.525064 accuracy: 0.593750 [700 / 938]\n",
      "loss: 1.561574 accuracy: 0.515625 [800 / 938]\n",
      "loss: 1.450850 accuracy: 0.656250 [900 / 938]\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 1.553944 accuracy: 0.578125 [0 / 938]\n",
      "loss: 1.512154 accuracy: 0.515625 [100 / 938]\n",
      "loss: 1.363111 accuracy: 0.671875 [200 / 938]\n",
      "loss: 1.435599 accuracy: 0.578125 [300 / 938]\n",
      "loss: 1.314276 accuracy: 0.656250 [400 / 938]\n",
      "loss: 1.317480 accuracy: 0.687500 [500 / 938]\n",
      "loss: 1.336384 accuracy: 0.640625 [600 / 938]\n",
      "loss: 1.263454 accuracy: 0.656250 [700 / 938]\n",
      "loss: 1.302209 accuracy: 0.546875 [800 / 938]\n",
      "loss: 1.208665 accuracy: 0.703125 [900 / 938]\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 1.314188 accuracy: 0.625000 [0 / 938]\n",
      "loss: 1.293252 accuracy: 0.500000 [100 / 938]\n",
      "loss: 1.124492 accuracy: 0.703125 [200 / 938]\n",
      "loss: 1.231258 accuracy: 0.593750 [300 / 938]\n",
      "loss: 1.112093 accuracy: 0.656250 [400 / 938]\n",
      "loss: 1.131916 accuracy: 0.703125 [500 / 938]\n",
      "loss: 1.159948 accuracy: 0.640625 [600 / 938]\n",
      "loss: 1.097475 accuracy: 0.656250 [700 / 938]\n",
      "loss: 1.139129 accuracy: 0.609375 [800 / 938]\n",
      "loss: 1.062053 accuracy: 0.718750 [900 / 938]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:dvclive:Error in cache: output 'model.pt' does not exist\n",
      "WARNING:dvclive:Can't use 'fmnist model' as artifact name (ID). It will not be included in the `artifacts` section.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def train(dataloader, model, loss_fn, metrics_fn, optimizer, live):\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "        accuracy = metrics_fn(pred, y)\n",
    "\n",
    "        # Backpropagation.\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch\n",
    "            # live.log_metric(\"loss\", f\"{loss:3f}\", step=(batch // 100))\n",
    "            # live.log_metric(\"accuracy\", f\"{accuracy:3f}\", step=(batch // 100))\n",
    "            print(\n",
    "                f\"loss: {loss:3f} accuracy: {accuracy:3f} [{current} / {len(dataloader)}]\"\n",
    "            )\n",
    "        \n",
    "        live.next_step()\n",
    "\n",
    "\n",
    "epochs = 5\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "metric_fn = Accuracy(task=\"multiclass\", num_classes=10).to(device)\n",
    "model = NeuralNetwork().to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)\n",
    "\n",
    "with Live(\"results/train\", report=\"notebook\", save_dvc_exp=False) as live:\n",
    "    params = {\n",
    "        \"epochs\": epochs,\n",
    "        \"learning_rate\": 1e-3,\n",
    "        \"batch_size\": 64,\n",
    "        \"loss_function\": loss_fn.__class__.__name__,\n",
    "        \"metric_function\": metric_fn.__class__.__name__,\n",
    "        \"optimizer\": \"SGD\",\n",
    "    }\n",
    "    # Log training parameters.\n",
    "    live.log_params(params)\n",
    "\n",
    "    for t in range(epochs):\n",
    "        print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "        train(train_dataloader, model, loss_fn, metric_fn, optimizer, live)\n",
    "\n",
    "    models_dir = Path(\"models\")\n",
    "    models_dir.mkdir(exist_ok=True)\n",
    "    torch.save(model,  (models_dir / \"model.pth\").absolute())\n",
    "\n",
    "    # Save the trained model to MLflow.\n",
    "    live.log_artifact(\n",
    "      \"models/model.pt\",\n",
    "      type=\"model\",\n",
    "      name=\"fmnist model\",\n",
    "      desc=\"fmnist trained model1\",\n",
    "      labels=[\"fmnist\", \"DL\"],\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting pt model to ONNX format and registering to MLFLOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/spidey/.local/lib/python3.10/site-packages/torch/onnx/_internal/exporter.py:136: UserWarning: torch.onnx.dynamo_export only implements opset version 18 for now. If you need to use a different opset version, please register them with register_custom_op.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "input = torch.randn(1,1,28,28).to(device)\n",
    "onnx_program = torch.onnx.dynamo_export(model,input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx_program.save(\"fmnist.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "onnx_model = onnx.load(\"fmnist.onnx\")\n",
    "onnx.checker.check_model(onnx_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/05/30 15:08:13 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /tmp/tmp37d8vf6l/model, flavor: onnx). Fall back to return ['onnx==1.16.1', 'onnxruntime==1.18.0']. Set logging level to DEBUG to see the full traceback. \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<mlflow.models.model.ModelInfo at 0x7f16ba83cca0>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.onnx.log_model(onnx_model, \"pytorch_onnx_fmnist_model\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting ONNX to TensorRT format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "BATCH_SIZE=2\n",
    "PRECISION = np.float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: line 1: trtexec: command not found\n"
     ]
    }
   ],
   "source": [
    "!trtexec --onnx=fmnist.onnx --saveEngine=fmnist_engine.trt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-31 09:56:31.593689: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-31 09:56:31.649800: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-31 09:56:32.399750: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05/31/2024-09:56:36] [TRT] [W] CUDA lazy loading is not enabled. Enabling it can significantly reduce device memory usage and speed up TensorRT initialization. See \"Lazy Loading\" section of CUDA documentation https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#lazy-loading\n"
     ]
    }
   ],
   "source": [
    "from onnx_helper import ONNXClassifierWrapper\n",
    "N_CLASSES = 10 # Our ResNet-50 is trained on a 1000 class ImageNet task\n",
    "trt_model = ONNXClassifierWrapper(\"fmnist_engine.trt\", [BATCH_SIZE, N_CLASSES], target_dtype = PRECISION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE=2\n",
    "dummy_input_batch = np.zeros((BATCH_SIZE, 28, 28,1), dtype = PRECISION)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05/31/2024-09:56:37] [TRT] [E] 3: [executionContext.cpp::enqueueV3::2491] Error Code 3: API Usage Error (Parameter check failed at: runtime/api/executionContext.cpp::enqueueV3::2491, condition: (mContext.profileObliviousBindings.at(profileObliviousIndex)) != nullptr )\n"
     ]
    }
   ],
   "source": [
    "predictions = trt_model.predict(dummy_input_batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'ONNXClassifierWrapper' object has no attribute 'graph'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[59], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmlflow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43monnx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrt_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpytorch_onnx_trt_fmnist_model\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/mlflow/onnx/__init__.py:514\u001b[0m, in \u001b[0;36mlog_model\u001b[0;34m(onnx_model, artifact_path, conda_env, code_paths, registered_model_name, signature, input_example, await_registration_for, pip_requirements, extra_pip_requirements, onnx_execution_providers, onnx_session_options, metadata, save_as_external_data)\u001b[0m\n\u001b[1;32m    441\u001b[0m \u001b[38;5;129m@format_docstring\u001b[39m(LOG_MODEL_PARAM_DOCS\u001b[38;5;241m.\u001b[39mformat(package_name\u001b[38;5;241m=\u001b[39mFLAVOR_NAME))\n\u001b[1;32m    442\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlog_model\u001b[39m(\n\u001b[1;32m    443\u001b[0m     onnx_model,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    456\u001b[0m     save_as_external_data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    457\u001b[0m ):\n\u001b[1;32m    458\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    459\u001b[0m \u001b[38;5;124;03m    Log an ONNX model as an MLflow artifact for the current run.\u001b[39;00m\n\u001b[1;32m    460\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[38;5;124;03m        metadata of the logged model.\u001b[39;00m\n\u001b[1;32m    513\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 514\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mModel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    515\u001b[0m \u001b[43m        \u001b[49m\u001b[43martifact_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43martifact_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    516\u001b[0m \u001b[43m        \u001b[49m\u001b[43mflavor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmlflow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43monnx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    517\u001b[0m \u001b[43m        \u001b[49m\u001b[43monnx_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43monnx_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    518\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconda_env\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconda_env\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    519\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcode_paths\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcode_paths\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    520\u001b[0m \u001b[43m        \u001b[49m\u001b[43mregistered_model_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mregistered_model_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    521\u001b[0m \u001b[43m        \u001b[49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    522\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_example\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_example\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m        \u001b[49m\u001b[43mawait_registration_for\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mawait_registration_for\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpip_requirements\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpip_requirements\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    525\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_pip_requirements\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_pip_requirements\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    526\u001b[0m \u001b[43m        \u001b[49m\u001b[43monnx_execution_providers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43monnx_execution_providers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[43m        \u001b[49m\u001b[43monnx_session_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43monnx_session_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    528\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    529\u001b[0m \u001b[43m        \u001b[49m\u001b[43msave_as_external_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_as_external_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    530\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/mlflow/models/model.py:665\u001b[0m, in \u001b[0;36mModel.log\u001b[0;34m(cls, artifact_path, flavor, registered_model_name, await_registration_for, metadata, run_id, resources, **kwargs)\u001b[0m\n\u001b[1;32m    661\u001b[0m     run_id \u001b[38;5;241m=\u001b[39m mlflow\u001b[38;5;241m.\u001b[39mtracking\u001b[38;5;241m.\u001b[39mfluent\u001b[38;5;241m.\u001b[39m_get_or_start_run()\u001b[38;5;241m.\u001b[39minfo\u001b[38;5;241m.\u001b[39mrun_id\n\u001b[1;32m    662\u001b[0m mlflow_model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m(\n\u001b[1;32m    663\u001b[0m     artifact_path\u001b[38;5;241m=\u001b[39martifact_path, run_id\u001b[38;5;241m=\u001b[39mrun_id, metadata\u001b[38;5;241m=\u001b[39mmetadata, resources\u001b[38;5;241m=\u001b[39mresources\n\u001b[1;32m    664\u001b[0m )\n\u001b[0;32m--> 665\u001b[0m \u001b[43mflavor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmlflow_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmlflow_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    667\u001b[0m \u001b[38;5;66;03m# Copy model metadata files to a sub-directory 'metadata',\u001b[39;00m\n\u001b[1;32m    668\u001b[0m \u001b[38;5;66;03m# For UC sharing use-cases.\u001b[39;00m\n\u001b[1;32m    669\u001b[0m metadata_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(local_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/mlflow/onnx/__init__.py:176\u001b[0m, in \u001b[0;36msave_model\u001b[0;34m(onnx_model, path, conda_env, code_paths, mlflow_model, signature, input_example, pip_requirements, extra_pip_requirements, onnx_execution_providers, onnx_session_options, metadata, save_as_external_data)\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;66;03m# Save onnx-model\u001b[39;00m\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m Version(onnx\u001b[38;5;241m.\u001b[39m__version__) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m Version(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1.9.0\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 176\u001b[0m     \u001b[43monnx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43monnx_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_data_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_as_external_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_as_external_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    178\u001b[0m     onnx\u001b[38;5;241m.\u001b[39msave_model(onnx_model, model_data_path)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/onnx/__init__.py:318\u001b[0m, in \u001b[0;36msave_model\u001b[0;34m(proto, f, format, save_as_external_data, all_tensors_to_one_file, location, size_threshold, convert_attribute)\u001b[0m\n\u001b[1;32m    315\u001b[0m     proto \u001b[38;5;241m=\u001b[39m _get_serializer(_DEFAULT_FORMAT)\u001b[38;5;241m.\u001b[39mdeserialize_proto(proto, ModelProto())\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m save_as_external_data:\n\u001b[0;32m--> 318\u001b[0m     \u001b[43mconvert_model_to_external_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    319\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproto\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mall_tensors_to_one_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize_threshold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert_attribute\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    322\u001b[0m model_filepath \u001b[38;5;241m=\u001b[39m _get_file_path(f)\n\u001b[1;32m    323\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m model_filepath \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/onnx/external_data_helper.py:135\u001b[0m, in \u001b[0;36mconvert_model_to_external_data\u001b[0;34m(model, all_tensors_to_one_file, location, size_threshold, convert_attribute)\u001b[0m\n\u001b[1;32m    131\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    132\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlocation must be a relative path that is relative to the model path.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    133\u001b[0m         )\n\u001b[1;32m    134\u001b[0m     file_name \u001b[38;5;241m=\u001b[39m location\n\u001b[0;32m--> 135\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m tensor \u001b[38;5;129;01min\u001b[39;00m tensors:\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    137\u001b[0m         tensor\u001b[38;5;241m.\u001b[39mHasField(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_data\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    138\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m sys\u001b[38;5;241m.\u001b[39mgetsizeof(tensor\u001b[38;5;241m.\u001b[39mraw_data) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m size_threshold\n\u001b[1;32m    139\u001b[0m     ):\n\u001b[1;32m    140\u001b[0m         set_external_data(tensor, file_name)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/onnx/external_data_helper.py:236\u001b[0m, in \u001b[0;36m_get_initializer_tensors\u001b[0;34m(onnx_model_proto)\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_initializer_tensors\u001b[39m(onnx_model_proto: ModelProto) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterable[TensorProto]:\n\u001b[1;32m    235\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Create an iterator of initializer tensors from ONNX model.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 236\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m _get_initializer_tensors_from_graph(\u001b[43monnx_model_proto\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgraph\u001b[49m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'ONNXClassifierWrapper' object has no attribute 'graph'"
     ]
    }
   ],
   "source": [
    "mlflow.onnx.log_model(trt_model, \"pytorch_onnx_trt_fmnist_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'mlflow.deployments' has no attribute 'create_deployment'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#import mlflow.deployments\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m deployment \u001b[38;5;241m=\u001b[39m \u001b[43mmlflow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdeployments\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_deployment\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfmnist_deployment_trt\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodels:/fmnist_model/1\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtriton\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'mlflow.deployments' has no attribute 'create_deployment'"
     ]
    }
   ],
   "source": [
    "#import mlflow.deployments\n",
    "import mlflow.deployments\n",
    "\n",
    "\n",
    "mlflow.deployments.create\n",
    "\n",
    "deployment = mlflow.deployments.create_deployment(\"fmnist_deployment_trt\",\"models:/fmnist_model/1\",\"triton\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
