{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"AWS_ACCESS_KEY_ID\"] = \"ASIASVE4GYTVDIVDR7LL\"\n",
    "os.environ[\"AWS_SECRET_ACCESS_KEY\"] = \"heDjikxWLoQ0TclzsIVmrOMqI4xEDTzfB3kFsvZa\"\n",
    "os.environ[\"AWS_SESSION_TOKEN\"] = \"IQoJb3JpZ2luX2VjEKr//////////wEaCXVzLWVhc3QtMSJIMEYCIQD4ZJs1M0fOCriMCu1ybsJX4Bnur014I0rrc2foRolYQwIhAKNHOh3IlRfB0i4eaj4tPpc3/N9pl4NSSNhWI7AgU/ciKpwDCDMQAhoMMTgyODYzNzA5NDE4IgzowdvibXC2dkq8XoAq+QJheaj8t7mCsbixYRPAPvmFR2i3Az7BbIlldF3LZQkZZ4FTiN+VXmtnb+D7eYUSGGF0Ba58Xu0DfaGA76Py+wNAz+BvbSzXDW1vh3DWIOQ3bHxOldnWNIr/D07uogHL4ghFatBR8X8Opi88M3WQZyABXdWoeyi1zv99mgqOhKedNFiqrnyaIM8ZVX1iZ2qmBq6zaGbJjxTeZtvCiz4gdzcaNOo4PFgWKJoGYl7VbBHA/FrofWuNwqaQH1Gb5x+Y25TqneQIFL79YZfIJWwgB81pYQAVRYEbCcAOGw2gyjtPK37IsrmzZm8ltJhwg4mklBCFtjKa68c54xosB2EzjAzBht0wHCI6g49jjylHBoJ5VCIyrPzrpIDVANU2scpfCuliJq3LC5mCK3OQ5a2TNgVjk71qTbXoqSIipkVLozgPXle2oxWO6EUQ48QL+B5IQTlyjKA7RJHFlR+6CznkcWKiO/h8xeW3KgUeRU+ZFUMRBmly1/cRACFxKTDR/eKyBjqlAda1njg2Qigo/DW39JGx2YvIOWJm61n2r4UY4iTVWPZ/1kGpqaomeS/QHp4FDH1TuV2JX36KNluSLC0NJca94Ign3y3MU3DrD3xOUGuLxk6k+NEu23FbVopu/tyIRgdNkQB76a26wzUpVPY+E+2nWTrVJaN2Iua2voagiP5GTpC2t0hPqxwIYD0zzypJKOVOj/nmSmKNjHEmXD6yS2B0ZVyPPfKSOA==\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-08-13 11:45:59 182863709418-us-east-1-personalizemanagedvod\n",
      "2021-06-04 15:07:44 2917f415d1744fc6b112daf5d69bfaa7\n",
      "2022-06-27 11:45:51 activity-monitoring\n",
      "2022-08-03 11:33:13 amplify-amplifyappming-prod-163307-deployment\n",
      "2021-07-26 14:53:48 amplify-beholder-prod-145340-deployment\n",
      "2022-11-08 10:06:34 amplify-materia-dev-100627-deployment\n",
      "2022-12-01 15:53:01 amplify-muscovlm-dev-155255-deployment\n",
      "2022-12-01 15:50:24 amplify-muscovlm-staging-215018-deployment\n",
      "2024-04-05 11:43:19 amplify-uascheduler-dev-114312-deployment\n",
      "2024-04-15 12:37:15 amplify-uawebcloud-devcloud-cd42b-deployment\n",
      "2022-09-12 13:56:34 annotation-umpire-assist\n",
      "2023-06-16 09:23:12 api-doc-plana\n",
      "2022-07-20 15:35:01 api-pipeline-stack-pipelineartifactsbucket-1eakfvsfk91fu\n",
      "2022-07-20 15:34:38 api-pipeline-stack-pipelineartifactsloggingbucket-btiur0psopx0\n",
      "2024-02-23 09:58:56 apollo-files-dev\n",
      "2022-12-05 11:02:21 aps-build\n",
      "2023-03-14 09:58:26 aps-support\n",
      "2021-12-06 14:19:34 aws-cloudtrail-logs-182863709418-0475e14f\n",
      "2021-11-08 13:55:44 aws-glue-assets-182863709418-us-east-2\n",
      "2022-07-20 11:44:41 aws-sam-cli-managed-default-samclisourcebucket-9g95ujdpqe5t\n",
      "2024-01-05 15:31:00 aws-sam-cli-managed-default-samclisourcebucket-ifyawpq9ga9b\n",
      "2022-07-20 14:30:27 aws-sam-cli-managed-dev-pi-artifactsloggingbucket-12e7rkhjh8s8c\n",
      "2022-07-20 14:30:51 aws-sam-cli-managed-dev-pipeline-artifactsbucket-2birr5eecd7l\n",
      "2022-07-20 15:11:48 aws-sam-cli-managed-prod-p-artifactsloggingbucket-1dx1qn5n3yvrh\n",
      "2022-07-20 15:12:12 aws-sam-cli-managed-prod-pipeline-artifactsbucket-9ycihq318d68\n",
      "2021-07-22 10:47:42 beholder.musco.cloud\n",
      "2021-12-20 09:21:48 blueframe\n",
      "2022-02-17 13:32:26 camera-configuration\n",
      "2024-05-01 23:35:24 camera-simulator\n",
      "2022-06-07 14:09:34 cdk-hnb659fds-assets-182863709418-us-east-2\n",
      "2021-06-09 09:12:51 cf-templates-5njx94o3snse-us-east-1\n",
      "2022-07-21 11:15:51 cf-templates-5njx94o3snse-us-east-2\n",
      "2021-08-18 11:52:03 count-data\n",
      "2021-07-21 14:32:54 count.musco.cloud\n",
      "2021-09-13 14:53:12 crowdcounting.logging\n",
      "2021-09-13 14:52:48 crowdcounting.musco.cloud\n",
      "2023-07-08 12:48:24 curateddata-182863709418-us-east-1-9d21c200\n",
      "2021-06-21 15:57:14 custom-labels-console-us-east-1-4eaba81f9e\n",
      "2021-12-16 14:49:26 elasticbeanstalk-us-east-2-182863709418\n",
      "2021-02-26 15:29:46 elasticbeanstalk-us-west-2-182863709418\n",
      "2024-02-28 12:06:20 etech.vr\n",
      "2021-12-01 10:56:06 game-footage\n",
      "2023-10-26 11:34:40 gitlab-runner-lamda-deployments\n",
      "2024-05-28 14:58:27 gly-lucid-camera-illuminance\n",
      "2021-09-22 15:34:23 grass-health\n",
      "2023-07-18 09:44:12 halcyon-adhoc-timestream-query-results\n",
      "2021-11-01 15:33:53 intern-resume\n",
      "2021-06-11 15:26:55 ipvideobucket\n",
      "2023-07-06 23:41:43 lesson-001\n",
      "2021-06-09 09:14:11 livestream-logsbucket-1w2i8y406gron\n",
      "2021-06-08 15:28:51 livestreaming-logsbucket-ighz4lb4jfe9\n",
      "2022-08-02 09:41:24 materia-musco\n",
      "2022-11-14 09:54:02 ml.ops.test\n",
      "2024-05-29 15:32:44 mlflow-test-registry\n",
      "2023-07-18 15:28:08 mlop-bank\n",
      "2021-07-14 15:22:25 musco-drone-images\n",
      "2021-08-02 14:25:51 musco-ml-data\n",
      "2021-07-14 15:39:38 musco-presage\n",
      "2023-04-13 13:42:44 musco-upload-test\n",
      "2021-07-21 11:26:47 musco.cloud\n",
      "2023-02-02 11:28:46 musco.plana\n",
      "2024-03-05 12:41:43 musco.planb\n",
      "2022-06-07 14:36:35 muscoming\n",
      "2022-06-16 13:24:55 muscominglambda\n",
      "2023-07-08 12:48:24 nyctaxitrips-182863709418-us-east-1-9d21c200\n",
      "2023-12-15 03:11:32 playcorps-synced\n",
      "2023-12-15 01:59:06 playcorps-unsynced\n",
      "2021-09-14 11:22:49 serverlessrepo-sample-s3bucket-1o8hojfcf0cg9\n",
      "2024-05-20 15:13:59 sovereign-artifacts\n",
      "2024-03-26 11:25:41 test-gly\n",
      "2023-06-12 13:27:36 test-gly-uploadvideotest\n",
      "2021-07-22 10:33:44 turfview.musco.cloud\n",
      "2023-10-03 09:33:59 umpire-assist-configs\n",
      "2022-10-12 11:46:19 umpire-assist-releases\n",
      "2024-01-31 13:39:28 umpire-assist-weights\n",
      "2021-07-21 10:27:34 www.musco.cloud\n",
      "2023-07-10 09:55:54 yolo-tracking\n",
      "2023-06-29 11:37:05 yolobank-s3\n"
     ]
    }
   ],
   "source": [
    "!aws s3 ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:8080\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AWS Session\n",
    "import boto3\n",
    "\n",
    "aws_session = boto3.Session(\n",
    "    profile_name='AWSAdministratorAccess-182863709418',\n",
    "    region_name='us-east-1'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sets the current active experiment to the \"Apple_Models\" experiment and\n",
    "# returns the Experiment metadata\n",
    "experiment = mlflow.set_experiment(\"fmnist_pytorch_Models2\")\n",
    "\n",
    "# Define a run name for this iteration of training.\n",
    "# If this is not set, a unique name will be auto-generated for your run.\n",
    "run_name = \"fmnist_nn_test_s4\"\n",
    "\n",
    "# Define an artifact path that the model will be saved to.\n",
    "#artifact_path = \"fmnist_nn\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of buckets:\n",
      "182863709418-us-east-1-personalizemanagedvod\n",
      "2917f415d1744fc6b112daf5d69bfaa7\n",
      "activity-monitoring\n",
      "amplify-amplifyappming-prod-163307-deployment\n",
      "amplify-beholder-prod-145340-deployment\n",
      "amplify-materia-dev-100627-deployment\n",
      "amplify-muscovlm-dev-155255-deployment\n",
      "amplify-muscovlm-staging-215018-deployment\n",
      "amplify-uascheduler-dev-114312-deployment\n",
      "amplify-uawebcloud-devcloud-cd42b-deployment\n",
      "annotation-umpire-assist\n",
      "api-doc-plana\n",
      "api-pipeline-stack-pipelineartifactsbucket-1eakfvsfk91fu\n",
      "api-pipeline-stack-pipelineartifactsloggingbucket-btiur0psopx0\n",
      "apollo-files-dev\n",
      "aps-build\n",
      "aps-support\n",
      "aws-cloudtrail-logs-182863709418-0475e14f\n",
      "aws-glue-assets-182863709418-us-east-2\n",
      "aws-sam-cli-managed-default-samclisourcebucket-9g95ujdpqe5t\n",
      "aws-sam-cli-managed-default-samclisourcebucket-ifyawpq9ga9b\n",
      "aws-sam-cli-managed-dev-pi-artifactsloggingbucket-12e7rkhjh8s8c\n",
      "aws-sam-cli-managed-dev-pipeline-artifactsbucket-2birr5eecd7l\n",
      "aws-sam-cli-managed-prod-p-artifactsloggingbucket-1dx1qn5n3yvrh\n",
      "aws-sam-cli-managed-prod-pipeline-artifactsbucket-9ycihq318d68\n",
      "beholder.musco.cloud\n",
      "blueframe\n",
      "camera-configuration\n",
      "camera-simulator\n",
      "cdk-hnb659fds-assets-182863709418-us-east-2\n",
      "cf-templates-5njx94o3snse-us-east-1\n",
      "cf-templates-5njx94o3snse-us-east-2\n",
      "count-data\n",
      "count.musco.cloud\n",
      "crowdcounting.logging\n",
      "crowdcounting.musco.cloud\n",
      "curateddata-182863709418-us-east-1-9d21c200\n",
      "custom-labels-console-us-east-1-4eaba81f9e\n",
      "elasticbeanstalk-us-east-2-182863709418\n",
      "elasticbeanstalk-us-west-2-182863709418\n",
      "etech.vr\n",
      "game-footage\n",
      "gitlab-runner-lamda-deployments\n",
      "gly-lucid-camera-illuminance\n",
      "grass-health\n",
      "halcyon-adhoc-timestream-query-results\n",
      "intern-resume\n",
      "ipvideobucket\n",
      "lesson-001\n",
      "livestream-logsbucket-1w2i8y406gron\n",
      "livestreaming-logsbucket-ighz4lb4jfe9\n",
      "materia-musco\n",
      "ml.ops.test\n",
      "mlflow-test-registry\n",
      "mlop-bank\n",
      "musco-drone-images\n",
      "musco-ml-data\n",
      "musco-presage\n",
      "musco-upload-test\n",
      "musco.cloud\n",
      "musco.plana\n",
      "musco.planb\n",
      "muscoming\n",
      "muscominglambda\n",
      "nyctaxitrips-182863709418-us-east-1-9d21c200\n",
      "playcorps-synced\n",
      "playcorps-unsynced\n",
      "serverlessrepo-sample-s3bucket-1o8hojfcf0cg9\n",
      "sovereign-artifacts\n",
      "test-gly\n",
      "test-gly-uploadvideotest\n",
      "turfview.musco.cloud\n",
      "umpire-assist-configs\n",
      "umpire-assist-releases\n",
      "umpire-assist-weights\n",
      "www.musco.cloud\n",
      "yolo-tracking\n",
      "yolobank-s3\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "\n",
    "def list_buckets():\n",
    "    s3 = aws_session.client('s3')\n",
    "    response = s3.list_buckets()\n",
    "    buckets = [bucket['Name'] for bucket in response['Buckets']]\n",
    "    return buckets\n",
    "\n",
    "buckets = list_buckets()\n",
    "\n",
    "if buckets:\n",
    "    print(\"List of buckets:\")\n",
    "    for bucket in buckets:\n",
    "        print(bucket)\n",
    "else:\n",
    "    print(\"No buckets found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File 'model_summary.txt' uploaded successfully to bucket 'mlflow-test-registry' as 'summary'.\n"
     ]
    }
   ],
   "source": [
    "def upload_file_to_bucket(file_path, bucket_name, object_name=None):\n",
    "    if object_name is None:\n",
    "        object_name = file_path\n",
    "\n",
    "    s3 = aws_session.client('s3')\n",
    "    try:\n",
    "        s3.upload_file(file_path, bucket_name, object_name)\n",
    "        print(f\"File '{file_path}' uploaded successfully to bucket '{bucket_name}' as '{object_name}'.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to upload file '{file_path}' to bucket '{bucket_name}': {e}\")\n",
    "\n",
    "# Example usage\n",
    "file_path = 'model_summary.txt'  # Specify the path to your file\n",
    "bucket_name = 'mlflow-test-registry'     # Specify the name of your bucket\n",
    "object_name = 'summary'             # Optional: Specify the name you want the file to have in the bucket\n",
    "\n",
    "upload_file_to_bucket(file_path, bucket_name, object_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.303796 accuracy: 0.109375 [0 / 938]\n",
      "loss: 2.296122 accuracy: 0.093750 [100 / 938]\n",
      "loss: 2.278434 accuracy: 0.078125 [200 / 938]\n",
      "loss: 2.271420 accuracy: 0.093750 [300 / 938]\n",
      "loss: 2.257466 accuracy: 0.140625 [400 / 938]\n",
      "loss: 2.228515 accuracy: 0.250000 [500 / 938]\n",
      "loss: 2.235048 accuracy: 0.281250 [600 / 938]\n",
      "loss: 2.202355 accuracy: 0.453125 [700 / 938]\n",
      "loss: 2.207278 accuracy: 0.343750 [800 / 938]\n",
      "loss: 2.169353 accuracy: 0.453125 [900 / 938]\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 2.178684 accuracy: 0.359375 [0 / 938]\n",
      "loss: 2.168372 accuracy: 0.453125 [100 / 938]\n",
      "loss: 2.120343 accuracy: 0.531250 [200 / 938]\n",
      "loss: 2.130924 accuracy: 0.531250 [300 / 938]\n",
      "loss: 2.072251 accuracy: 0.609375 [400 / 938]\n",
      "loss: 2.029145 accuracy: 0.578125 [500 / 938]\n",
      "loss: 2.040469 accuracy: 0.609375 [600 / 938]\n",
      "loss: 1.970006 accuracy: 0.671875 [700 / 938]\n",
      "loss: 1.975915 accuracy: 0.468750 [800 / 938]\n",
      "loss: 1.891940 accuracy: 0.609375 [900 / 938]\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 1.939120 accuracy: 0.500000 [0 / 938]\n",
      "loss: 1.904571 accuracy: 0.593750 [100 / 938]\n",
      "loss: 1.800898 accuracy: 0.640625 [200 / 938]\n",
      "loss: 1.823655 accuracy: 0.578125 [300 / 938]\n",
      "loss: 1.706495 accuracy: 0.640625 [400 / 938]\n",
      "loss: 1.677256 accuracy: 0.640625 [500 / 938]\n",
      "loss: 1.676743 accuracy: 0.625000 [600 / 938]\n",
      "loss: 1.591248 accuracy: 0.593750 [700 / 938]\n",
      "loss: 1.609681 accuracy: 0.546875 [800 / 938]\n",
      "loss: 1.494713 accuracy: 0.687500 [900 / 938]\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 1.599670 accuracy: 0.625000 [0 / 938]\n",
      "loss: 1.558637 accuracy: 0.562500 [100 / 938]\n",
      "loss: 1.419052 accuracy: 0.671875 [200 / 938]\n",
      "loss: 1.470270 accuracy: 0.593750 [300 / 938]\n",
      "loss: 1.356657 accuracy: 0.656250 [400 / 938]\n",
      "loss: 1.365098 accuracy: 0.656250 [500 / 938]\n",
      "loss: 1.365178 accuracy: 0.640625 [600 / 938]\n",
      "loss: 1.297988 accuracy: 0.656250 [700 / 938]\n",
      "loss: 1.330520 accuracy: 0.562500 [800 / 938]\n",
      "loss: 1.226856 accuracy: 0.734375 [900 / 938]\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 1.343580 accuracy: 0.625000 [0 / 938]\n",
      "loss: 1.316341 accuracy: 0.578125 [100 / 938]\n",
      "loss: 1.159171 accuracy: 0.687500 [200 / 938]\n",
      "loss: 1.245327 accuracy: 0.625000 [300 / 938]\n",
      "loss: 1.131846 accuracy: 0.656250 [400 / 938]\n",
      "loss: 1.161464 accuracy: 0.703125 [500 / 938]\n",
      "loss: 1.174682 accuracy: 0.656250 [600 / 938]\n",
      "loss: 1.115396 accuracy: 0.671875 [700 / 938]\n",
      "loss: 1.156201 accuracy: 0.609375 [800 / 938]\n",
      "loss: 1.067722 accuracy: 0.750000 [900 / 938]\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "import torch\n",
    "\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchinfo import summary\n",
    "from torchmetrics import Accuracy\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "# Download training data from open datasets.\n",
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "\n",
    "# Create data loaders.\n",
    "train_dataloader = DataLoader(training_data, batch_size=64)\n",
    "\n",
    "# Get cpu or gpu for training.\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "\n",
    "# Define the model.\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28 * 28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "\n",
    "def train(dataloader, model, loss_fn, metrics_fn, optimizer):\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "        accuracy = metrics_fn(pred, y)\n",
    "\n",
    "        # Backpropagation.\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch\n",
    "            mlflow.log_metric(\"loss\", f\"{loss:3f}\", step=(batch // 100))\n",
    "            mlflow.log_metric(\"accuracy\", f\"{accuracy:3f}\", step=(batch // 100))\n",
    "            print(\n",
    "                f\"loss: {loss:3f} accuracy: {accuracy:3f} [{current} / {len(dataloader)}]\"\n",
    "            )\n",
    "\n",
    "\n",
    "epochs = 5\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "metric_fn = Accuracy(task=\"multiclass\", num_classes=10).to(device)\n",
    "model = NeuralNetwork().to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)\n",
    "\n",
    "with mlflow.start_run(run_name=run_name):\n",
    "    params = {\n",
    "        \"epochs\": epochs,\n",
    "        \"learning_rate\": 1e-3,\n",
    "        \"batch_size\": 64,\n",
    "        \"loss_function\": loss_fn.__class__.__name__,\n",
    "        \"metric_function\": metric_fn.__class__.__name__,\n",
    "        \"optimizer\": \"SGD\",\n",
    "    }\n",
    "    # Log training parameters.\n",
    "    mlflow.log_params(params)\n",
    "\n",
    "    # Log model summary.\n",
    "    with open(\"model_summary.txt\", \"w\") as f:\n",
    "        f.write(str(summary(model)))\n",
    "    mlflow.log_artifact(\"model_summary.txt\")\n",
    "\n",
    "    for t in range(epochs):\n",
    "        print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "        train(train_dataloader, model, loss_fn, metric_fn, optimizer)\n",
    "\n",
    "    # Save the trained model to MLflow.\n",
    "    mlflow.pytorch.log_model(model, \"pytorch_fmnist_model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Successfully registered model 'fmnist_model'.\n",
      "2024/05/30 13:59:44 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: fmnist_model, version 1\n",
      "Created version '1' of model 'fmnist_model'.\n"
     ]
    }
   ],
   "source": [
    "results = mlflow.register_model(\"runs:/ba6e55728ccc4a7ebb1da835098befb2/fmnist_nn_test_s4\",\"fmnist_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting pt model to ONNX format and registering to MLFLOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/spidey/.local/lib/python3.10/site-packages/torch/onnx/_internal/exporter.py:136: UserWarning: torch.onnx.dynamo_export only implements opset version 18 for now. If you need to use a different opset version, please register them with register_custom_op.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "input = torch.randn(1,1,28,28).to(device)\n",
    "onnx_program = torch.onnx.dynamo_export(model,input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx_program.save(\"fmnist.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "onnx_model = onnx.load(\"fmnist.onnx\")\n",
    "onnx.checker.check_model(onnx_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/05/30 15:08:13 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /tmp/tmp37d8vf6l/model, flavor: onnx). Fall back to return ['onnx==1.16.1', 'onnxruntime==1.18.0']. Set logging level to DEBUG to see the full traceback. \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<mlflow.models.model.ModelInfo at 0x7f16ba83cca0>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.onnx.log_model(onnx_model, \"pytorch_onnx_fmnist_model\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting ONNX to TensorRT format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "BATCH_SIZE=2\n",
    "PRECISION = np.float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: line 1: trtexec: command not found\n"
     ]
    }
   ],
   "source": [
    "!trtexec --onnx=fmnist.onnx --saveEngine=fmnist_engine.trt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-31 09:56:31.593689: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-31 09:56:31.649800: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-31 09:56:32.399750: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05/31/2024-09:56:36] [TRT] [W] CUDA lazy loading is not enabled. Enabling it can significantly reduce device memory usage and speed up TensorRT initialization. See \"Lazy Loading\" section of CUDA documentation https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#lazy-loading\n"
     ]
    }
   ],
   "source": [
    "from onnx_helper import ONNXClassifierWrapper\n",
    "N_CLASSES = 10 # Our ResNet-50 is trained on a 1000 class ImageNet task\n",
    "trt_model = ONNXClassifierWrapper(\"fmnist_engine.trt\", [BATCH_SIZE, N_CLASSES], target_dtype = PRECISION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE=2\n",
    "dummy_input_batch = np.zeros((BATCH_SIZE, 28, 28,1), dtype = PRECISION)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05/31/2024-09:56:37] [TRT] [E] 3: [executionContext.cpp::enqueueV3::2491] Error Code 3: API Usage Error (Parameter check failed at: runtime/api/executionContext.cpp::enqueueV3::2491, condition: (mContext.profileObliviousBindings.at(profileObliviousIndex)) != nullptr )\n"
     ]
    }
   ],
   "source": [
    "predictions = trt_model.predict(dummy_input_batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'ONNXClassifierWrapper' object has no attribute 'graph'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[59], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmlflow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43monnx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrt_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpytorch_onnx_trt_fmnist_model\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/mlflow/onnx/__init__.py:514\u001b[0m, in \u001b[0;36mlog_model\u001b[0;34m(onnx_model, artifact_path, conda_env, code_paths, registered_model_name, signature, input_example, await_registration_for, pip_requirements, extra_pip_requirements, onnx_execution_providers, onnx_session_options, metadata, save_as_external_data)\u001b[0m\n\u001b[1;32m    441\u001b[0m \u001b[38;5;129m@format_docstring\u001b[39m(LOG_MODEL_PARAM_DOCS\u001b[38;5;241m.\u001b[39mformat(package_name\u001b[38;5;241m=\u001b[39mFLAVOR_NAME))\n\u001b[1;32m    442\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlog_model\u001b[39m(\n\u001b[1;32m    443\u001b[0m     onnx_model,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    456\u001b[0m     save_as_external_data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    457\u001b[0m ):\n\u001b[1;32m    458\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    459\u001b[0m \u001b[38;5;124;03m    Log an ONNX model as an MLflow artifact for the current run.\u001b[39;00m\n\u001b[1;32m    460\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[38;5;124;03m        metadata of the logged model.\u001b[39;00m\n\u001b[1;32m    513\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 514\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mModel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    515\u001b[0m \u001b[43m        \u001b[49m\u001b[43martifact_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43martifact_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    516\u001b[0m \u001b[43m        \u001b[49m\u001b[43mflavor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmlflow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43monnx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    517\u001b[0m \u001b[43m        \u001b[49m\u001b[43monnx_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43monnx_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    518\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconda_env\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconda_env\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    519\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcode_paths\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcode_paths\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    520\u001b[0m \u001b[43m        \u001b[49m\u001b[43mregistered_model_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mregistered_model_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    521\u001b[0m \u001b[43m        \u001b[49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    522\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_example\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_example\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m        \u001b[49m\u001b[43mawait_registration_for\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mawait_registration_for\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpip_requirements\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpip_requirements\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    525\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_pip_requirements\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_pip_requirements\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    526\u001b[0m \u001b[43m        \u001b[49m\u001b[43monnx_execution_providers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43monnx_execution_providers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[43m        \u001b[49m\u001b[43monnx_session_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43monnx_session_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    528\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    529\u001b[0m \u001b[43m        \u001b[49m\u001b[43msave_as_external_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_as_external_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    530\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/mlflow/models/model.py:665\u001b[0m, in \u001b[0;36mModel.log\u001b[0;34m(cls, artifact_path, flavor, registered_model_name, await_registration_for, metadata, run_id, resources, **kwargs)\u001b[0m\n\u001b[1;32m    661\u001b[0m     run_id \u001b[38;5;241m=\u001b[39m mlflow\u001b[38;5;241m.\u001b[39mtracking\u001b[38;5;241m.\u001b[39mfluent\u001b[38;5;241m.\u001b[39m_get_or_start_run()\u001b[38;5;241m.\u001b[39minfo\u001b[38;5;241m.\u001b[39mrun_id\n\u001b[1;32m    662\u001b[0m mlflow_model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m(\n\u001b[1;32m    663\u001b[0m     artifact_path\u001b[38;5;241m=\u001b[39martifact_path, run_id\u001b[38;5;241m=\u001b[39mrun_id, metadata\u001b[38;5;241m=\u001b[39mmetadata, resources\u001b[38;5;241m=\u001b[39mresources\n\u001b[1;32m    664\u001b[0m )\n\u001b[0;32m--> 665\u001b[0m \u001b[43mflavor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmlflow_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmlflow_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    667\u001b[0m \u001b[38;5;66;03m# Copy model metadata files to a sub-directory 'metadata',\u001b[39;00m\n\u001b[1;32m    668\u001b[0m \u001b[38;5;66;03m# For UC sharing use-cases.\u001b[39;00m\n\u001b[1;32m    669\u001b[0m metadata_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(local_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/mlflow/onnx/__init__.py:176\u001b[0m, in \u001b[0;36msave_model\u001b[0;34m(onnx_model, path, conda_env, code_paths, mlflow_model, signature, input_example, pip_requirements, extra_pip_requirements, onnx_execution_providers, onnx_session_options, metadata, save_as_external_data)\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;66;03m# Save onnx-model\u001b[39;00m\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m Version(onnx\u001b[38;5;241m.\u001b[39m__version__) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m Version(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1.9.0\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 176\u001b[0m     \u001b[43monnx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43monnx_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_data_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_as_external_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_as_external_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    178\u001b[0m     onnx\u001b[38;5;241m.\u001b[39msave_model(onnx_model, model_data_path)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/onnx/__init__.py:318\u001b[0m, in \u001b[0;36msave_model\u001b[0;34m(proto, f, format, save_as_external_data, all_tensors_to_one_file, location, size_threshold, convert_attribute)\u001b[0m\n\u001b[1;32m    315\u001b[0m     proto \u001b[38;5;241m=\u001b[39m _get_serializer(_DEFAULT_FORMAT)\u001b[38;5;241m.\u001b[39mdeserialize_proto(proto, ModelProto())\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m save_as_external_data:\n\u001b[0;32m--> 318\u001b[0m     \u001b[43mconvert_model_to_external_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    319\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproto\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mall_tensors_to_one_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize_threshold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert_attribute\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    322\u001b[0m model_filepath \u001b[38;5;241m=\u001b[39m _get_file_path(f)\n\u001b[1;32m    323\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m model_filepath \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/onnx/external_data_helper.py:135\u001b[0m, in \u001b[0;36mconvert_model_to_external_data\u001b[0;34m(model, all_tensors_to_one_file, location, size_threshold, convert_attribute)\u001b[0m\n\u001b[1;32m    131\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    132\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlocation must be a relative path that is relative to the model path.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    133\u001b[0m         )\n\u001b[1;32m    134\u001b[0m     file_name \u001b[38;5;241m=\u001b[39m location\n\u001b[0;32m--> 135\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m tensor \u001b[38;5;129;01min\u001b[39;00m tensors:\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    137\u001b[0m         tensor\u001b[38;5;241m.\u001b[39mHasField(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_data\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    138\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m sys\u001b[38;5;241m.\u001b[39mgetsizeof(tensor\u001b[38;5;241m.\u001b[39mraw_data) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m size_threshold\n\u001b[1;32m    139\u001b[0m     ):\n\u001b[1;32m    140\u001b[0m         set_external_data(tensor, file_name)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/onnx/external_data_helper.py:236\u001b[0m, in \u001b[0;36m_get_initializer_tensors\u001b[0;34m(onnx_model_proto)\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_initializer_tensors\u001b[39m(onnx_model_proto: ModelProto) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterable[TensorProto]:\n\u001b[1;32m    235\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Create an iterator of initializer tensors from ONNX model.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 236\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m _get_initializer_tensors_from_graph(\u001b[43monnx_model_proto\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgraph\u001b[49m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'ONNXClassifierWrapper' object has no attribute 'graph'"
     ]
    }
   ],
   "source": [
    "mlflow.onnx.log_model(trt_model, \"pytorch_onnx_trt_fmnist_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'mlflow.deployments' has no attribute 'create_deployment'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#import mlflow.deployments\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m deployment \u001b[38;5;241m=\u001b[39m \u001b[43mmlflow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdeployments\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_deployment\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfmnist_deployment_trt\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodels:/fmnist_model/1\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtriton\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'mlflow.deployments' has no attribute 'create_deployment'"
     ]
    }
   ],
   "source": [
    "#import mlflow.deployments\n",
    "import mlflow.deployments\n",
    "\n",
    "\n",
    "mlflow.deployments.create\n",
    "\n",
    "deployment = mlflow.deployments.create_deployment(\"fmnist_deployment_trt\",\"models:/fmnist_model/1\",\"triton\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
